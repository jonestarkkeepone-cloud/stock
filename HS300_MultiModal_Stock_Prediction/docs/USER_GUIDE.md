# ğŸ“– HS300 å¤šæ¨¡æ€è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ - ç”¨æˆ·ä½¿ç”¨æŒ‡å—

## ğŸ¯ å¿«é€Ÿå¯¼èˆª

- [æ–°æ‰‹å…¥é—¨](#æ–°æ‰‹å…¥é—¨) - 5åˆ†é’Ÿå¿«é€Ÿä½“éªŒ
- [å®Œæ•´æ•™ç¨‹](#å®Œæ•´æ•™ç¨‹) - è¯¦ç»†ä½¿ç”¨æ­¥éª¤
- [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½) - è¿›é˜¶ä½¿ç”¨æŠ€å·§
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜) - é—®é¢˜è§£å†³æ–¹æ¡ˆ

---

## æ–°æ‰‹å…¥é—¨

### âš¡ 5åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

```bash
# 1. å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
pip install -r requirements.txt

# 2. æå–è‚¡ç¥¨æ•°æ®ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
python extract_stocks.py

# 3. å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ˆ3ä¸ªè‚¡ç¥¨ï¼Œ3è½®è®­ç»ƒï¼Œçº¦2åˆ†é’Ÿï¼‰
python train.py --mode train --epochs 3 --stocks 3

# 4. æŸ¥çœ‹è®­ç»ƒç»“æœ
python visualize.py --results ./results/results.json
```

### ğŸ“Š é¢„æœŸç»“æœ

è¿è¡ŒæˆåŠŸåï¼Œæ‚¨å°†çœ‹åˆ°ï¼š
- è®­ç»ƒæŸå¤±ä»çº¦1.0é™åˆ°0.2ä»¥ä¸‹
- RÂ²æŒ‡æ ‡è¾¾åˆ°0.8+
- ç”Ÿæˆé¢„æµ‹vsçœŸå®å€¼çš„å¯¹æ¯”å›¾
- ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°`./checkpoints/`

---

## å®Œæ•´æ•™ç¨‹

### ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒå‡†å¤‡

#### 1.1 æ£€æŸ¥ç³»ç»Ÿè¦æ±‚

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.8+ï¼‰
python --version

# æ£€æŸ¥å¯ç”¨å†…å­˜ï¼ˆæ¨è8GB+ï¼‰
# Windows
wmic computersystem get TotalPhysicalMemory
# Linux
free -h
```

#### 1.2 å®‰è£…ä¾èµ–

```bash
# åŸºç¡€å®‰è£…
pip install -r requirements.txt

# é«˜çº§åŠŸèƒ½ï¼ˆå¯é€‰ï¼Œéœ€è¦æ›´å¤šå†…å­˜ï¼‰
pip install transformers timm
```

### ç¬¬äºŒæ­¥ï¼šæ•°æ®å‡†å¤‡

#### 2.1 æ•°æ®ç›®å½•ç»“æ„

ç¡®ä¿æ‚¨çš„æ•°æ®ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
parent_directory/
â”œâ”€â”€ Finmultime/                    # æ‚¨çš„æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ time_series/
â”‚   â”‚   â””â”€â”€ HS300_time_series/
â”‚   â”‚       â””â”€â”€ HS300_time_series/
â”‚   â”‚           â”œâ”€â”€ 600000.SS.csv  # ä¸Šæµ·è‚¡ç¥¨
â”‚   â”‚           â”œâ”€â”€ 000001.SZ.csv  # æ·±åœ³è‚¡ç¥¨
â”‚   â”‚           â””â”€â”€ ...
â”‚   â”œâ”€â”€ image/
â”‚   â”‚   â””â”€â”€ HS300_image/
â”‚   â”‚       â””â”€â”€ HS300_image/
â”‚   â”‚           â”œâ”€â”€ 600000.SS.png
â”‚   â”‚           â””â”€â”€ ...
â”‚   â”œâ”€â”€ text/
â”‚   â”‚   â””â”€â”€ hs300news_summary/
â”‚   â”‚       â””â”€â”€ hs300news_summary/
â”‚   â”‚           â”œâ”€â”€ 600000.SS.jsonl
â”‚   â”‚           â””â”€â”€ ...
â”‚   â””â”€â”€ table/
â”‚       â””â”€â”€ hs300_tabular/
â”‚           â””â”€â”€ hs300_tabular/
â”‚               â”œâ”€â”€ 600000.SS/
â”‚               â”‚   â””â”€â”€ income.jsonl
â”‚               â””â”€â”€ ...
â””â”€â”€ HS300_MultiModal_Stock_Prediction/  # æœ¬é¡¹ç›®
```

#### 2.2 æå–å®Œæ•´æ•°æ®è‚¡ç¥¨

```bash
# æ‰«ææ•°æ®ç›®å½•ï¼Œæ‰¾å‡ºå…·æœ‰å®Œæ•´å››æ¨¡æ€æ•°æ®çš„è‚¡ç¥¨
python extract_stocks.py

# æŸ¥çœ‹æå–ç»“æœ
python -c "
import json
with open('hs300_complete_stocks.json', 'r') as f:
    stocks = json.load(f)
print(f'æ‰¾åˆ° {len(stocks)} ä¸ªå®Œæ•´å››æ¨¡æ€è‚¡ç¥¨')
print('å‰5ä¸ªè‚¡ç¥¨:', list(stocks.keys())[:5])
"
```

### ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹è®­ç»ƒ

#### 3.1 å¿«é€Ÿæµ‹è¯•è®­ç»ƒ

```bash
# ä½¿ç”¨3ä¸ªè‚¡ç¥¨è¿›è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆçº¦2-5åˆ†é’Ÿï¼‰
python train.py --mode train --epochs 3 --stocks 3 --batch_size 16

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/training.log
```

#### 3.2 å°è§„æ¨¡è®­ç»ƒ

```bash
# ä½¿ç”¨10ä¸ªè‚¡ç¥¨è¿›è¡Œå°è§„æ¨¡è®­ç»ƒï¼ˆçº¦30-60åˆ†é’Ÿï¼‰
python train.py --mode train --epochs 20 --stocks 10 --batch_size 32

# ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
python train.py --mode train --epochs 20 --stocks 10 --device cuda
```

#### 3.3 å®Œæ•´è®­ç»ƒ

```bash
# ä½¿ç”¨æ‰€æœ‰å¯ç”¨è‚¡ç¥¨è¿›è¡Œå®Œæ•´è®­ç»ƒï¼ˆçº¦2-6å°æ—¶ï¼‰
python train.py --mode train --epochs 100 --batch_size 64

# åå°è¿è¡Œï¼ˆLinux/Macï¼‰
nohup python train.py --mode train --epochs 100 > training.log 2>&1 &

# åå°è¿è¡Œï¼ˆWindows PowerShellï¼‰
Start-Process python -ArgumentList "train.py --mode train --epochs 100" -WindowStyle Hidden
```

### ç¬¬å››æ­¥ï¼šæ¨¡å‹è¯„ä¼°

#### 4.1 åŸºç¡€è¯„ä¼°

```bash
# è¯„ä¼°æœ€ä½³æ¨¡å‹
python evaluate.py --checkpoint ./checkpoints/best_model.pt

# è¯„ä¼°ç‰¹å®šæ£€æŸ¥ç‚¹
python evaluate.py --checkpoint ./checkpoints/epoch_50.pt
```

#### 4.2 è¯¦ç»†åˆ†æ

```bash
# ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š
python evaluate.py --checkpoint ./checkpoints/best_model.pt --detailed

# æŒ‰è‚¡ç¥¨åˆ†ææ€§èƒ½
python evaluate.py --checkpoint ./checkpoints/best_model.pt --by_stock
```

### ç¬¬äº”æ­¥ï¼šç»“æœå¯è§†åŒ–

#### 5.1 åŸºç¡€å¯è§†åŒ–

```bash
# ç”Ÿæˆæ‰€æœ‰åŸºç¡€å›¾è¡¨
python visualize.py --results ./results/results.json

# åªç”Ÿæˆè®­ç»ƒæ›²çº¿
python visualize.py --results ./results/results.json --plot_type training

# åªç”Ÿæˆé¢„æµ‹å¯¹æ¯”å›¾
python visualize.py --results ./results/results.json --plot_type prediction
```

#### 5.2 é«˜çº§å¯è§†åŒ–

```bash
# ç”Ÿæˆäº¤äº’å¼å›¾è¡¨ï¼ˆéœ€è¦å®‰è£…plotlyï¼‰
pip install plotly
python visualize.py --results ./results/results.json --interactive

# ç”Ÿæˆè‚¡ç¥¨çº§åˆ«çš„è¯¦ç»†åˆ†æ
python visualize.py --results ./results/results.json --stock_analysis
```

---

## é«˜çº§åŠŸèƒ½

### ğŸ§  ä½¿ç”¨é«˜çº§æ¨¡å‹

#### å¯ç”¨BERTæ–‡æœ¬ç¼–ç 

```bash
# å®‰è£…transformers
pip install transformers

# ä½¿ç”¨é«˜çº§é…ç½®è®­ç»ƒ
python -c "
from configs.advanced_config import get_advanced_config
config = get_advanced_config()
config.model.use_bert = True
# ä¿å­˜é…ç½®å¹¶è®­ç»ƒ...
"
```

#### å¯ç”¨é¢„è®­ç»ƒå›¾åƒæ¨¡å‹

```bash
# å®‰è£…timm
pip install timm

# ä½¿ç”¨é¢„è®­ç»ƒå›¾åƒç¼–ç å™¨
python -c "
from configs.advanced_config import get_advanced_config
config = get_advanced_config()
config.model.use_pretrained_image = True
# è®­ç»ƒ...
"
```

### ğŸ“Š è‡ªå®šä¹‰é…ç½®

#### åˆ›å»ºè‡ªå®šä¹‰é…ç½®æ–‡ä»¶

```python
# custom_config.py
from configs.config import Config

def get_custom_config():
    config = Config()
    
    # æ•°æ®é…ç½®
    config.data.seq_length = 60        # ä½¿ç”¨60å¤©å†å²æ•°æ®
    config.data.pred_horizon = 5       # é¢„æµ‹5å¤©
    
    # æ¨¡å‹é…ç½®
    config.model.hidden_size = 256     # æ›´å¤§çš„éšè—å±‚
    config.model.num_layers = 3        # æ›´æ·±çš„ç½‘ç»œ
    
    # è®­ç»ƒé…ç½®
    config.train.learning_rate = 0.0005  # æ›´å°çš„å­¦ä¹ ç‡
    config.train.batch_size = 16        # æ›´å°çš„æ‰¹é‡
    
    return config

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
if __name__ == "__main__":
    config = get_custom_config()
    # å¼€å§‹è®­ç»ƒ...
```

### ğŸ”§ æ€§èƒ½ä¼˜åŒ–

#### GPUåŠ é€Ÿ

```bash
# æ£€æŸ¥GPUå¯ç”¨æ€§
python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"

# ä½¿ç”¨GPUè®­ç»ƒ
python train.py --device cuda --batch_size 128

# å¤šGPUè®­ç»ƒï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
python train.py --device cuda --multi_gpu
```

#### æ··åˆç²¾åº¦è®­ç»ƒ

```bash
# å¯ç”¨æ··åˆç²¾åº¦ï¼ˆèŠ‚çœæ˜¾å­˜ï¼ŒåŠ é€Ÿè®­ç»ƒï¼‰
python train.py --mixed_precision --batch_size 256
```

#### å†…å­˜ä¼˜åŒ–

```bash
# å‡å°‘å†…å­˜ä½¿ç”¨
python train.py --batch_size 8 --num_workers 2 --pin_memory False

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¨¡æ‹Ÿå¤§æ‰¹é‡ï¼‰
python train.py --batch_size 8 --gradient_accumulation_steps 8  # ç­‰æ•ˆbatch_size=64
```

---

## å¸¸è§é—®é¢˜

### â“ å®‰è£…é—®é¢˜

**Q: å®‰è£…PyTorchæ—¶å‡ºç°CUDAç‰ˆæœ¬ä¸åŒ¹é…**

A: æ£€æŸ¥CUDAç‰ˆæœ¬å¹¶å®‰è£…å¯¹åº”çš„PyTorchï¼š
```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi

# å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„PyTorch
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# CPUç‰ˆæœ¬
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

**Q: å®‰è£…transformerså¤±è´¥**

A: ä½¿ç”¨å›½å†…é•œåƒæºï¼š
```bash
pip install transformers -i https://pypi.tuna.tsinghua.edu.cn/simple/
```

### â“ æ•°æ®é—®é¢˜

**Q: æå–è‚¡ç¥¨æ—¶æ˜¾ç¤º"æ‰¾åˆ°0ä¸ªå®Œæ•´å››æ¨¡æ€è‚¡ç¥¨"**

A: æ£€æŸ¥æ•°æ®ç›®å½•è·¯å¾„ï¼š
```bash
# æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
ls ../Finmultime/

# ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®è·¯å¾„
# ç¼–è¾‘ configs/config.pyï¼Œä¿®æ”¹ data_dir å‚æ•°
```

**Q: è®­ç»ƒæ—¶å‡ºç°"æ•°æ®åŠ è½½å¤±è´¥"**

A: æ£€æŸ¥æ•°æ®æ–‡ä»¶å®Œæ•´æ€§ï¼š
```bash
# è¿è¡Œæ•°æ®è¯Šæ–­è„šæœ¬
python -c "
from data.dataset import FinMultiTimeDataset
from configs.config import Config

config = Config()
try:
    dataset = FinMultiTimeDataset(
        data_dir=config.data.data_dir,
        market=config.data.market,
        stocks=['600000'],  # æµ‹è¯•å•ä¸ªè‚¡ç¥¨
        start_date='2020-01-01',
        end_date='2020-12-31'
    )
    print(f'âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(dataset)}')
except Exception as e:
    print(f'âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}')
"
```

### â“ è®­ç»ƒé—®é¢˜

**Q: è®­ç»ƒè¿‡ç¨‹ä¸­å†…å­˜ä¸è¶³**

A: å‡å°‘å†…å­˜ä½¿ç”¨ï¼š
```bash
# æ–¹æ³•1ï¼šå‡å°‘æ‰¹é‡å¤§å°
python train.py --batch_size 8

# æ–¹æ³•2ï¼šå‡å°‘å·¥ä½œè¿›ç¨‹
python train.py --num_workers 1

# æ–¹æ³•3ï¼šä½¿ç”¨åŸºç¡€é…ç½®
python train.py --config basic
```

**Q: è®­ç»ƒæŸå¤±ä¸ä¸‹é™**

A: è°ƒæ•´å­¦ä¹ ç‡å’Œæ£€æŸ¥æ•°æ®ï¼š
```bash
# é™ä½å­¦ä¹ ç‡
python train.py --lr 0.0001

# å¢åŠ è®­ç»ƒè½®æ¬¡
python train.py --epochs 200

# æ£€æŸ¥æ•°æ®è´¨é‡
python -c "
import torch
from data.dataset import FinMultiTimeDataset
# æ£€æŸ¥æ•°æ®åˆ†å¸ƒ...
"
```

**Q: GPUæ˜¾å­˜ä¸è¶³**

A: ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨ï¼š
```bash
# å‡å°‘æ‰¹é‡å¤§å°
python train.py --batch_size 16

# å¯ç”¨æ··åˆç²¾åº¦
python train.py --mixed_precision

# ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
python train.py --gradient_checkpointing
```

### â“ ç»“æœé—®é¢˜

**Q: æ¨¡å‹æ€§èƒ½ä¸ç†æƒ³**

A: å°è¯•ä»¥ä¸‹ä¼˜åŒ–ï¼š
```bash
# 1. å¢åŠ æ¨¡å‹å¤æ‚åº¦
python train.py --hidden_size 256 --num_layers 3

# 2. ä½¿ç”¨æ›´é•¿çš„å†å²æ•°æ®
python train.py --seq_length 60

# 3. å¯ç”¨é«˜çº§åŠŸèƒ½
pip install transformers timm
python train.py --config advanced

# 4. è°ƒæ•´å­¦ä¹ ç‡
python train.py --lr 0.0005
```

**Q: é¢„æµ‹ç»“æœä¸ç¨³å®š**

A: æé«˜æ¨¡å‹ç¨³å®šæ€§ï¼š
```bash
# 1. å¢åŠ è®­ç»ƒæ•°æ®
python train.py --stocks 50

# 2. ä½¿ç”¨æ›´å¤šè®­ç»ƒè½®æ¬¡
python train.py --epochs 200

# 3. æ·»åŠ æ­£åˆ™åŒ–
python train.py --weight_decay 0.01 --dropout 0.3

# 4. ä½¿ç”¨é›†æˆæ–¹æ³•
python train.py --ensemble 5
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### ä¸åŒé…ç½®çš„é¢„æœŸæ€§èƒ½

| é…ç½® | è‚¡ç¥¨æ•° | è®­ç»ƒæ—¶é—´ | RÂ² | æ–¹å‘å‡†ç¡®ç‡ | å†…å­˜éœ€æ±‚ |
|------|--------|----------|-----|-----------|----------|
| **å¿«é€Ÿæµ‹è¯•** | 3 | 2-5åˆ†é’Ÿ | 0.75+ | 85%+ | 4GB |
| **å°è§„æ¨¡** | 10 | 30-60åˆ†é’Ÿ | 0.80+ | 87%+ | 8GB |
| **ä¸­ç­‰è§„æ¨¡** | 50 | 2-4å°æ—¶ | 0.82+ | 88%+ | 16GB |
| **å®Œæ•´è®­ç»ƒ** | 464 | 4-8å°æ—¶ | 0.85+ | 90%+ | 32GB |

### ç¡¬ä»¶æ€§èƒ½å¯¹æ¯”

| ç¡¬ä»¶é…ç½® | è®­ç»ƒé€Ÿåº¦ | æ¨èç”¨é€” |
|----------|----------|----------|
| **CPU Only** | 1x | å¿«é€Ÿæµ‹è¯• |
| **GTX 1660** | 3x | å°è§„æ¨¡è®­ç»ƒ |
| **RTX 3080** | 8x | ä¸­ç­‰è§„æ¨¡è®­ç»ƒ |
| **RTX 4090** | 15x | å®Œæ•´è®­ç»ƒ |

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ–°æ‰‹å»ºè®®

1. **ä»å°å¼€å§‹**ï¼šå…ˆç”¨3ä¸ªè‚¡ç¥¨æµ‹è¯•ï¼Œç¡®ä¿æµç¨‹æ­£å¸¸
2. **æ£€æŸ¥æ•°æ®**ï¼šç¡®ä¿æ•°æ®ç›®å½•ç»“æ„æ­£ç¡®
3. **ç›‘æ§è®­ç»ƒ**ï¼šè§‚å¯ŸæŸå¤±æ›²çº¿ï¼ŒåŠæ—¶è°ƒæ•´å‚æ•°
4. **ä¿å­˜ç»“æœ**ï¼šå®šæœŸå¤‡ä»½æ¨¡å‹å’Œç»“æœ

### 2. è¿›é˜¶ç”¨æˆ·

1. **ä½¿ç”¨é«˜çº§åŠŸèƒ½**ï¼šå¯ç”¨BERTå’Œé¢„è®­ç»ƒæ¨¡å‹
2. **è°ƒä¼˜å‚æ•°**ï¼šæ ¹æ®æ•°æ®ç‰¹ç‚¹è°ƒæ•´æ¨¡å‹ç»“æ„
3. **é›†æˆæ–¹æ³•**ï¼šä½¿ç”¨å¤šä¸ªæ¨¡å‹é›†æˆæé«˜æ€§èƒ½
4. **è‡ªå®šä¹‰æŸå¤±**ï¼šæ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾è®¡æŸå¤±å‡½æ•°

### 3. ç”Ÿäº§éƒ¨ç½²

1. **æ¨¡å‹å‹ç¼©**ï¼šä½¿ç”¨é‡åŒ–å’Œå‰ªæå‡å°‘æ¨¡å‹å¤§å°
2. **æ¨ç†ä¼˜åŒ–**ï¼šä½¿ç”¨TensorRTæˆ–ONNXåŠ é€Ÿæ¨ç†
3. **ç›‘æ§ç³»ç»Ÿ**ï¼šå»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§
4. **ç‰ˆæœ¬ç®¡ç†**ï¼šä½¿ç”¨MLflowç®¡ç†æ¨¡å‹ç‰ˆæœ¬

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0  
**æœ€åæ›´æ–°**: 2025-10-08  
**æŠ€æœ¯æ”¯æŒ**: æŸ¥çœ‹GitHub Issuesæˆ–è”ç³»ç»´æŠ¤å›¢é˜Ÿ
