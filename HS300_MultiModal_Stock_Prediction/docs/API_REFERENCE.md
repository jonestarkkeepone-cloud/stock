# ğŸ“š API å‚è€ƒæ–‡æ¡£

## ğŸ¯ æ ¸å¿ƒAPIæ¦‚è§ˆ

### ä¸»è¦æ¨¡å—

- [æ•°æ®å¤„ç†](#æ•°æ®å¤„ç†) - æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- [æ¨¡å‹å®šä¹‰](#æ¨¡å‹å®šä¹‰) - ç¥ç»ç½‘ç»œæ¨¡å‹
- [è®­ç»ƒå·¥å…·](#è®­ç»ƒå·¥å…·) - è®­ç»ƒå’Œè¯„ä¼°
- [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†) - å‚æ•°é…ç½®
- [å·¥å…·å‡½æ•°](#å·¥å…·å‡½æ•°) - è¾…åŠ©åŠŸèƒ½

---

## æ•°æ®å¤„ç†

### FinMultiTimeDataset

å¤šæ¨¡æ€é‡‘èæ—¶åºæ•°æ®é›†ç±»ã€‚

```python
from data.dataset import FinMultiTimeDataset

dataset = FinMultiTimeDataset(
    data_dir: str,              # æ•°æ®ç›®å½•è·¯å¾„
    market: str,                # å¸‚åœºåç§°ï¼ˆå¦‚"HS300"ï¼‰
    stocks: List[str] = None,   # è‚¡ç¥¨åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåŠ è½½æ‰€æœ‰
    start_date: str,            # å¼€å§‹æ—¥æœŸ "YYYY-MM-DD"
    end_date: str,              # ç»“æŸæ—¥æœŸ "YYYY-MM-DD"
    seq_length: int = 30,       # å†å²åºåˆ—é•¿åº¦
    pred_horizon: int = 1,      # é¢„æµ‹æ—¶é—´è·¨åº¦
    use_cnn_features: bool = True,  # æ˜¯å¦ä½¿ç”¨CNNæå–å›¾åƒç‰¹å¾
    cnn_feature_dim: int = 64   # CNNç‰¹å¾ç»´åº¦
)
```

**æ–¹æ³•**:
- `__len__()` â†’ int: è¿”å›æ•°æ®é›†å¤§å°
- `__getitem__(idx)` â†’ dict: è·å–å•ä¸ªæ ·æœ¬
- `get_scaler(key)` â†’ StandardScaler: è·å–æ ‡å‡†åŒ–å™¨

**è¿”å›æ ¼å¼**:
```python
{
    'x': torch.Tensor,      # è¾“å…¥ç‰¹å¾ (seq_length, feature_dim)
    'y': torch.Tensor,      # ç›®æ ‡å€¼ (pred_horizon,)
    'stock': str,           # è‚¡ç¥¨ä»£ç 
    'date': str,            # æ—¥æœŸ
    'scaler_key': str       # æ ‡å‡†åŒ–å™¨é”®å
}
```

### create_dataloaders

åˆ›å»ºè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ•°æ®åŠ è½½å™¨ã€‚

```python
from data.dataloader import create_dataloaders

train_loader, val_loader, test_loader = create_dataloaders(
    dataset: FinMultiTimeDataset,   # æ•°æ®é›†
    batch_size: int = 32,           # æ‰¹é‡å¤§å°
    train_ratio: float = 0.7,       # è®­ç»ƒé›†æ¯”ä¾‹
    val_ratio: float = 0.2,         # éªŒè¯é›†æ¯”ä¾‹
    num_workers: int = 4,           # å·¥ä½œè¿›ç¨‹æ•°
    pin_memory: bool = True         # æ˜¯å¦å›ºå®šå†…å­˜
)
```

---

## æ¨¡å‹å®šä¹‰

### MultimodalTKANModel

åŸºç¡€å¤šæ¨¡æ€TKANæ¨¡å‹ã€‚

```python
from models.tkan_model import MultimodalTKANModel

model = MultimodalTKANModel(
    input_size: int,        # è¾“å…¥ç‰¹å¾ç»´åº¦
    hidden_size: int,       # éšè—å±‚ç»´åº¦
    output_size: int,       # è¾“å‡ºç»´åº¦
    num_layers: int = 2,    # TKANå±‚æ•°
    dropout: float = 0.2    # Dropoutæ¯”ä¾‹
)
```

**æ–¹æ³•**:
- `forward(x)` â†’ torch.Tensor: å‰å‘ä¼ æ’­
- `get_attention_weights()` â†’ torch.Tensor: è·å–æ³¨æ„åŠ›æƒé‡

### AdvancedMultimodalStockPredictor

é«˜çº§å¤šæ¨¡æ€è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ã€‚

```python
from models.advanced_model import AdvancedMultimodalStockPredictor

model = AdvancedMultimodalStockPredictor(
    time_series_dim: int = 6,       # æ—¶åºç‰¹å¾ç»´åº¦
    text_dim: int = 128,            # æ–‡æœ¬ç‰¹å¾ç»´åº¦
    image_dim: int = 64,            # å›¾åƒç‰¹å¾ç»´åº¦
    table_dim: int = 6,             # è´¢åŠ¡ç‰¹å¾ç»´åº¦
    fusion_embed_dim: int = 64,     # èåˆåµŒå…¥ç»´åº¦
    fusion_num_heads: int = 4,      # æ³¨æ„åŠ›å¤´æ•°
    tkan_hidden_size: int = 128,    # TKANéšè—ç»´åº¦
    use_bert: bool = False,         # æ˜¯å¦ä½¿ç”¨BERT
    use_pretrained_image: bool = False,  # æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒå›¾åƒæ¨¡å‹
    estimate_uncertainty: bool = True    # æ˜¯å¦ä¼°è®¡ä¸ç¡®å®šæ€§
)
```

**è¿”å›æ ¼å¼**:
```python
{
    'mean': torch.Tensor,           # é¢„æµ‹å‡å€¼
    'variance': torch.Tensor,       # é¢„æµ‹æ–¹å·®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    'confidence': torch.Tensor,     # ç½®ä¿¡åŒºé—´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    'attention_weights': dict       # æ³¨æ„åŠ›æƒé‡
}
```

### æ–‡æœ¬ç¼–ç å™¨

```python
from models.text_encoder import create_text_encoder

text_encoder = create_text_encoder(
    use_bert: bool = True,          # æ˜¯å¦ä½¿ç”¨BERT
    output_dim: int = 128,          # è¾“å‡ºç»´åº¦
    model_name: str = 'bert-base-chinese',  # é¢„è®­ç»ƒæ¨¡å‹åç§°
    max_length: int = 128,          # æœ€å¤§æ–‡æœ¬é•¿åº¦
    freeze_bert: bool = False       # æ˜¯å¦å†»ç»“BERTå‚æ•°
)
```

### å›¾åƒç¼–ç å™¨

```python
from models.image_encoder_advanced import create_image_encoder

image_encoder = create_image_encoder(
    feature_dim: int = 64,          # è¾“å‡ºç‰¹å¾ç»´åº¦
    use_pretrained: bool = True,    # æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
    pretrained_model: str = 'efficientnet_b0',  # é¢„è®­ç»ƒæ¨¡å‹åç§°
    use_ensemble: bool = False      # æ˜¯å¦ä½¿ç”¨é›†æˆæ¨¡å‹
)
```

---

## è®­ç»ƒå·¥å…·

### è®­ç»ƒå‡½æ•°

```python
# åŸºç¡€è®­ç»ƒ
from train import train_model

train_model(
    config: Config,                 # é…ç½®å¯¹è±¡
    model: nn.Module = None,        # æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    dataset: Dataset = None         # æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
)

# é«˜çº§è®­ç»ƒ
from train_advanced import train_advanced_model

model = train_advanced_model(
    config: AdvancedConfig,         # é«˜çº§é…ç½®å¯¹è±¡
    resume_from: str = None         # æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„
)
```

### è¯„ä¼°å‡½æ•°

```python
from evaluate import evaluate_model

results = evaluate_model(
    model: nn.Module,               # è®­ç»ƒå¥½çš„æ¨¡å‹
    test_loader: DataLoader,        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    device: str = 'cuda',           # è®¾å¤‡
    save_predictions: bool = True   # æ˜¯å¦ä¿å­˜é¢„æµ‹ç»“æœ
)
```

**è¿”å›æ ¼å¼**:
```python
{
    'mse': float,                   # å‡æ–¹è¯¯å·®
    'mae': float,                   # å¹³å‡ç»å¯¹è¯¯å·®
    'rmse': float,                  # å‡æ–¹æ ¹è¯¯å·®
    'r2': float,                    # å†³å®šç³»æ•°
    'direction_accuracy': float,    # æ–¹å‘å‡†ç¡®ç‡
    'sharpe_ratio': float,          # å¤æ™®æ¯”ç‡
    'max_drawdown': float,          # æœ€å¤§å›æ’¤
    'predictions': np.ndarray,      # é¢„æµ‹å€¼
    'targets': np.ndarray           # çœŸå®å€¼
}
```

---

## é…ç½®ç®¡ç†

### åŸºç¡€é…ç½®

```python
from configs.config import Config

config = Config()

# æ•°æ®é…ç½®
config.data.data_dir = "../Finmultime"
config.data.market = "HS300"
config.data.stocks = None  # æ‰€æœ‰è‚¡ç¥¨
config.data.start_date = "2019-01-01"
config.data.end_date = "2023-12-31"
config.data.seq_length = 30
config.data.pred_horizon = 1

# æ¨¡å‹é…ç½®
config.model.input_size = 77
config.model.hidden_size = 128
config.model.output_size = 1
config.model.num_layers = 2
config.model.dropout = 0.2

# è®­ç»ƒé…ç½®
config.train.batch_size = 32
config.train.epochs = 100
config.train.learning_rate = 0.001
config.train.device = 'cuda'
config.train.patience = 10
```

### é«˜çº§é…ç½®

```python
from configs.advanced_config import get_advanced_config, get_fast_test_config

# å®Œæ•´é«˜çº§é…ç½®
config = get_advanced_config()

# å¿«é€Ÿæµ‹è¯•é…ç½®
config = get_fast_test_config()

# è‡ªå®šä¹‰é…ç½®
config = get_advanced_config()
config.model.use_bert = True
config.model.use_pretrained_image = True
config.train.mixed_precision = True
```

---

## å·¥å…·å‡½æ•°

### è¯„ä¼°æŒ‡æ ‡

```python
from utils.metrics import calculate_comprehensive_metrics
from utils.financial_metrics import calculate_financial_metrics

# åŸºç¡€æŒ‡æ ‡
basic_metrics = calculate_comprehensive_metrics(
    y_true: torch.Tensor,           # çœŸå®å€¼
    y_pred: torch.Tensor            # é¢„æµ‹å€¼
)

# é‡‘èæŒ‡æ ‡
financial_metrics = calculate_financial_metrics(
    returns_true: np.ndarray,       # çœŸå®æ”¶ç›Šç‡
    returns_pred: np.ndarray,       # é¢„æµ‹æ”¶ç›Šç‡
    prices_true: np.ndarray = None, # çœŸå®ä»·æ ¼ï¼ˆå¯é€‰ï¼‰
    prices_pred: np.ndarray = None  # é¢„æµ‹ä»·æ ¼ï¼ˆå¯é€‰ï¼‰
)
```

### å¯è§†åŒ–å·¥å…·

```python
from utils.visualization import plot_training_history, plot_predictions

# ç»˜åˆ¶è®­ç»ƒå†å²
plot_training_history(
    train_losses: List[float],      # è®­ç»ƒæŸå¤±
    val_losses: List[float],        # éªŒè¯æŸå¤±
    save_path: str = None           # ä¿å­˜è·¯å¾„
)

# ç»˜åˆ¶é¢„æµ‹ç»“æœ
plot_predictions(
    y_true: np.ndarray,             # çœŸå®å€¼
    y_pred: np.ndarray,             # é¢„æµ‹å€¼
    dates: List[str] = None,        # æ—¥æœŸåˆ—è¡¨
    stock_name: str = None,         # è‚¡ç¥¨åç§°
    save_path: str = None           # ä¿å­˜è·¯å¾„
)
```

### æ•°æ®é¢„å¤„ç†

```python
from utils.preprocessing import MultimodalPreprocessor

preprocessor = MultimodalPreprocessor()

# æ—¶åºæ•°æ®æ ‡å‡†åŒ–
ts_normalized = preprocessor.fit_transform_time_series(
    data: np.ndarray,               # æ—¶åºæ•°æ®
    key: str                        # æ ‡å‡†åŒ–å™¨é”®å
)

# è´¢åŠ¡æ•°æ®æ ‡å‡†åŒ–
fund_normalized = preprocessor.fit_transform_fundamentals(
    data: np.ndarray,               # è´¢åŠ¡æ•°æ®
    key: str                        # æ ‡å‡†åŒ–å™¨é”®å
)

# åæ ‡å‡†åŒ–
original_data = preprocessor.inverse_transform(
    data: np.ndarray,               # æ ‡å‡†åŒ–åçš„æ•°æ®
    key: str                        # æ ‡å‡†åŒ–å™¨é”®å
)
```

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´è®­ç»ƒæµç¨‹

```python
import torch
from configs.config import Config
from data.dataset import FinMultiTimeDataset
from data.dataloader import create_dataloaders
from models.tkan_model import MultimodalTKANModel
from utils.metrics import calculate_comprehensive_metrics

# 1. åŠ è½½é…ç½®
config = Config()

# 2. åˆ›å»ºæ•°æ®é›†
dataset = FinMultiTimeDataset(
    data_dir=config.data.data_dir,
    market=config.data.market,
    stocks=config.data.stocks,
    start_date=config.data.start_date,
    end_date=config.data.end_date,
    seq_length=config.data.seq_length,
    pred_horizon=config.data.pred_horizon
)

# 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader, val_loader, test_loader = create_dataloaders(
    dataset, 
    batch_size=config.train.batch_size
)

# 4. åˆ›å»ºæ¨¡å‹
model = MultimodalTKANModel(
    input_size=config.model.input_size,
    hidden_size=config.model.hidden_size,
    output_size=config.model.output_size,
    num_layers=config.model.num_layers
)

# 5. è®­ç»ƒæ¨¡å‹
device = torch.device(config.train.device)
model.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=config.train.learning_rate)
criterion = torch.nn.MSELoss()

for epoch in range(config.train.epochs):
    # è®­ç»ƒå¾ªç¯...
    pass

# 6. è¯„ä¼°æ¨¡å‹
model.eval()
predictions, targets = [], []
with torch.no_grad():
    for batch in test_loader:
        x, y = batch['x'].to(device), batch['y'].to(device)
        pred = model(x)
        predictions.append(pred.cpu())
        targets.append(y.cpu())

predictions = torch.cat(predictions)
targets = torch.cat(targets)

# 7. è®¡ç®—æŒ‡æ ‡
metrics = calculate_comprehensive_metrics(targets, predictions)
print(f"RÂ²: {metrics['r2']:.4f}")
print(f"MSE: {metrics['mse']:.4f}")
```

### é«˜çº§æ¨¡å‹ä½¿ç”¨

```python
from configs.advanced_config import get_advanced_config
from models.advanced_model import AdvancedMultimodalStockPredictor

# åŠ è½½é«˜çº§é…ç½®
config = get_advanced_config()

# åˆ›å»ºé«˜çº§æ¨¡å‹
model = AdvancedMultimodalStockPredictor(
    time_series_dim=config.model.time_series_dim,
    text_dim=config.model.text_dim,
    image_dim=config.model.image_dim,
    table_dim=config.model.table_dim,
    use_bert=config.model.use_bert,
    use_pretrained_image=config.model.use_pretrained_image,
    estimate_uncertainty=config.model.estimate_uncertainty
)

# å‰å‘ä¼ æ’­
output = model(batch_data)
mean_pred = output['mean']
if config.model.estimate_uncertainty:
    variance_pred = output['variance']
    confidence_interval = output['confidence']
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### æ•°æ®æ ¼å¼è¦æ±‚

- **æ—¶åºæ•°æ®**: CSVæ ¼å¼ï¼ŒåŒ…å«Date, Open, High, Low, Close, Volumeåˆ—
- **å›¾åƒæ•°æ®**: PNGæ ¼å¼ï¼Œç°åº¦æˆ–RGB Kçº¿å›¾
- **æ–‡æœ¬æ•°æ®**: JSONLæ ¼å¼ï¼Œæ¯è¡ŒåŒ…å«æ—¥æœŸå’Œæ–°é—»æ–‡æœ¬
- **è´¢åŠ¡æ•°æ®**: JSONLæ ¼å¼ï¼ŒåŒ…å«åŸºæœ¬é¢æŒ‡æ ‡

### å†…å­˜ç®¡ç†

- å¤§æ‰¹é‡è®­ç»ƒæ—¶æ³¨æ„GPUå†…å­˜é™åˆ¶
- ä½¿ç”¨`pin_memory=False`å‡å°‘å†…å­˜ä½¿ç”¨
- è€ƒè™‘ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§æ‰¹é‡

### æ¨¡å‹ä¿å­˜

```python
# ä¿å­˜æ¨¡å‹
torch.save({
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'config': config,
    'epoch': epoch
}, 'model_checkpoint.pt')

# åŠ è½½æ¨¡å‹
checkpoint = torch.load('model_checkpoint.pt')
model.load_state_dict(checkpoint['model_state_dict'])
```

---

**APIç‰ˆæœ¬**: 2.0.0  
**æœ€åæ›´æ–°**: 2025-10-08  
**å…¼å®¹æ€§**: PyTorch 1.8+, Python 3.8+
