# ğŸ“š æ¨¡å—åŸç†ä¸ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»HS300å¤šæ¨¡æ€è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿä¸­æ¯ä¸ªæ ¸å¿ƒæ¨¡å—çš„åŸç†ã€ä½œç”¨å’Œä½¿ç”¨æ–¹æ³•ã€‚

## ğŸ“‹ ç›®å½•

1. [æ•°æ®å¤„ç†æ¨¡å—](#æ•°æ®å¤„ç†æ¨¡å—)
2. [æ¨¡å‹æ¶æ„æ¨¡å—](#æ¨¡å‹æ¶æ„æ¨¡å—)
3. [å·¥å…·å‡½æ•°æ¨¡å—](#å·¥å…·å‡½æ•°æ¨¡å—)
4. [é…ç½®ç®¡ç†æ¨¡å—](#é…ç½®ç®¡ç†æ¨¡å—)

---

## æ•°æ®å¤„ç†æ¨¡å—

### ğŸ“Š data/dataset.py - æ•°æ®é›†ç±»

#### æ ¸å¿ƒåŸç†
`FinMultiTimeDataset` æ˜¯æ•´ä¸ªç³»ç»Ÿçš„æ•°æ®æ ¸å¿ƒï¼Œè´Ÿè´£åŠ è½½å’Œé¢„å¤„ç†å››ç§æ¨¡æ€çš„æ•°æ®ï¼š

```python
# æ•°æ®æµç¨‹
åŸå§‹æ•°æ® â†’ æ•°æ®åŠ è½½ â†’ ç‰¹å¾æå– â†’ æ•°æ®å¯¹é½ â†’ æ»‘åŠ¨çª—å£ â†’ è®­ç»ƒæ ·æœ¬
```

#### ä¸»è¦åŠŸèƒ½

1. **å¤šæ¨¡æ€æ•°æ®åŠ è½½**
   - æ—¶åºæ•°æ®ï¼šä»CSVæ–‡ä»¶åŠ è½½OHLCVæ•°æ®
   - å›¾åƒæ•°æ®ï¼šä»PNGæ–‡ä»¶æå–CNNç‰¹å¾
   - æ–‡æœ¬æ•°æ®ï¼šä»JSONLæ–‡ä»¶åŠ è½½æ–°é—»æƒ…æ„Ÿåˆ†æ•°
   - è´¢åŠ¡æ•°æ®ï¼šä»JSONLæ–‡ä»¶åŠ è½½åŸºæœ¬é¢æŒ‡æ ‡

2. **æ•°æ®å¯¹é½å’ŒåŒæ­¥**
   - æŒ‰æ—¥æœŸå¯¹é½ä¸åŒæ¨¡æ€çš„æ•°æ®
   - å¤„ç†ç¼ºå¤±æ•°æ®å’Œå¼‚å¸¸å€¼
   - ç¡®ä¿æ—¶é—´åºåˆ—çš„è¿ç»­æ€§

3. **ç‰¹å¾å·¥ç¨‹**
   - æ—¶åºç‰¹å¾ï¼šä»·æ ¼å˜åŒ–ç‡ã€æŠ€æœ¯æŒ‡æ ‡
   - å›¾åƒç‰¹å¾ï¼šCNNæå–çš„64ç»´ç‰¹å¾å‘é‡
   - æ–‡æœ¬ç‰¹å¾ï¼šæƒ…æ„Ÿåˆ†æå¾—åˆ†
   - è´¢åŠ¡ç‰¹å¾ï¼šæ ‡å‡†åŒ–çš„åŸºæœ¬é¢æŒ‡æ ‡

#### ä½¿ç”¨ç¤ºä¾‹

```python
from data.dataset import FinMultiTimeDataset

# åˆ›å»ºæ•°æ®é›†
dataset = FinMultiTimeDataset(
    data_dir="../Finmultime",
    market="HS300",
    stocks=None,  # åŠ è½½æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
    start_date="2019-01-01",
    end_date="2023-12-31",
    seq_length=30,  # 30å¤©å†å²æ•°æ®
    pred_horizon=1  # é¢„æµ‹1å¤©
)

print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
print(f"è¾“å…¥ç»´åº¦: {dataset[0]['x'].shape}")
print(f"è¾“å‡ºç»´åº¦: {dataset[0]['y'].shape}")
```

#### å…³é”®å‚æ•°è¯´æ˜

- `seq_length`: å†å²åºåˆ—é•¿åº¦ï¼Œå†³å®šæ¨¡å‹èƒ½çœ‹åˆ°å¤šé•¿çš„å†å²
- `pred_horizon`: é¢„æµ‹æ—¶é—´è·¨åº¦ï¼Œé€šå¸¸è®¾ä¸º1ï¼ˆé¢„æµ‹ä¸‹ä¸€å¤©ï¼‰
- `use_cnn_features`: æ˜¯å¦ä½¿ç”¨CNNæå–å›¾åƒç‰¹å¾
- `cnn_feature_dim`: CNNç‰¹å¾ç»´åº¦ï¼Œé»˜è®¤64

### ğŸ”„ data/dataloader.py - æ•°æ®åŠ è½½å™¨

#### æ ¸å¿ƒåŸç†
æä¾›é«˜æ•ˆçš„æ‰¹é‡æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ç®¡é“ï¼š

```python
# æ•°æ®åŠ è½½æµç¨‹
æ•°æ®é›† â†’ æ‰¹é‡é‡‡æ · â†’ æ•°æ®å¢å¼º â†’ å¼ é‡è½¬æ¢ â†’ GPUä¼ è¾“
```

#### ä¸»è¦åŠŸèƒ½

1. **æ‰¹é‡æ•°æ®åŠ è½½**
   - æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡ŒåŠ è½½
   - å†…å­˜ä¼˜åŒ–çš„æ•°æ®ç¼“å­˜
   - åŠ¨æ€æ‰¹é‡å¤§å°è°ƒæ•´

2. **æ•°æ®å¢å¼º**
   - æ—¶åºæ•°æ®ï¼šæ·»åŠ å™ªå£°ã€æ—¶é—´æ‰­æ›²
   - å›¾åƒæ•°æ®ï¼šæ—‹è½¬ã€ç¼©æ”¾ã€é¢œè‰²å˜æ¢
   - æ–‡æœ¬æ•°æ®ï¼šæƒ…æ„Ÿåˆ†æ•°æ‰°åŠ¨

3. **è®­ç»ƒ/éªŒè¯åˆ†å‰²**
   - æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
   - è‚¡ç¥¨çº§åˆ«åˆ†å‰²
   - äº¤å‰éªŒè¯æ”¯æŒ

#### ä½¿ç”¨ç¤ºä¾‹

```python
from data.dataloader import create_dataloaders

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader, val_loader, test_loader = create_dataloaders(
    dataset=dataset,
    batch_size=32,
    train_ratio=0.7,
    val_ratio=0.2,
    num_workers=4
)

# è®­ç»ƒå¾ªç¯
for batch in train_loader:
    x, y = batch['x'], batch['y']
    # æ¨¡å‹è®­ç»ƒ...
```

---

## æ¨¡å‹æ¶æ„æ¨¡å—

### ğŸ§  models/tkan_model.py - TKANæ ¸å¿ƒæ¨¡å‹

#### æ ¸å¿ƒåŸç†
TKAN (Temporal Kolmogorov-Arnold Networks) æ˜¯æœ¬ç³»ç»Ÿçš„æ ¸å¿ƒæ—¶åºå»ºæ¨¡ç»„ä»¶ï¼š

```
è¾“å…¥åºåˆ— â†’ TKANå±‚1 â†’ TKANå±‚2 â†’ ... â†’ è¾“å‡ºå±‚ â†’ é¢„æµ‹ç»“æœ
    â†“         â†“         â†“              â†“         â†“
  å¤šæ¨¡æ€    æ—¶åºå»ºæ¨¡   éçº¿æ€§å˜æ¢      ç‰¹å¾èåˆ   è‚¡ä»·é¢„æµ‹
```

#### TKANåŸç†è¯¦è§£

1. **Kolmogorov-Arnoldè¡¨ç¤ºå®šç†**
   - ä»»ä½•å¤šå˜é‡è¿ç»­å‡½æ•°éƒ½å¯ä»¥è¡¨ç¤ºä¸ºå•å˜é‡å‡½æ•°çš„ç»„åˆ
   - TKANå°†æ­¤ç†è®ºåº”ç”¨äºæ—¶åºæ•°æ®å»ºæ¨¡

2. **æ—¶åºæ³¨æ„åŠ›æœºåˆ¶**
   ```python
   # æ³¨æ„åŠ›è®¡ç®—
   Q = XW_q  # æŸ¥è¯¢çŸ©é˜µ
   K = XW_k  # é”®çŸ©é˜µ
   V = XW_v  # å€¼çŸ©é˜µ
   
   Attention = softmax(QK^T / âˆšd_k)V
   ```

3. **éçº¿æ€§æ¿€æ´»å‡½æ•°å­¦ä¹ **
   - ä¼ ç»Ÿç¥ç»ç½‘ç»œï¼šå›ºå®šæ¿€æ´»å‡½æ•°ï¼ˆReLUã€Sigmoidç­‰ï¼‰
   - TKANï¼šå­¦ä¹ æœ€ä¼˜çš„æ¿€æ´»å‡½æ•°å½¢çŠ¶

#### æ¨¡å‹ç»“æ„

```python
class MultimodalTKANModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers):
        # TKANå±‚å †å 
        self.tkan_layers = nn.ModuleList([
            TKANLayer(input_size if i==0 else hidden_size, hidden_size)
            for i in range(num_layers)
        ])
        
        # è¾“å‡ºå±‚
        self.fc_out = nn.Linear(hidden_size, output_size)
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from models.tkan_model import MultimodalTKANModel

# åˆ›å»ºæ¨¡å‹
model = MultimodalTKANModel(
    input_size=77,      # 6+64+1+6 (æ—¶åº+å›¾åƒ+æ–‡æœ¬+è´¢åŠ¡)
    hidden_size=128,    # éšè—å±‚ç»´åº¦
    output_size=1,      # é¢„æµ‹1å¤©æ”¶ç›Šç‡
    num_layers=2        # TKANå±‚æ•°
)

# å‰å‘ä¼ æ’­
x = torch.randn(32, 30, 77)  # (batch, seq_len, features)
predictions = model(x)        # (batch, 1)
```

### ğŸ”— models/advanced_model.py - é«˜çº§å¤šæ¨¡æ€æ¨¡å‹

#### æ ¸å¿ƒåŸç†
æ•´åˆæ‰€æœ‰å…ˆè¿›æŠ€æœ¯çš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼š

```
å„æ¨¡æ€è¾“å…¥ â†’ ç‹¬ç«‹ç¼–ç  â†’ æ³¨æ„åŠ›èåˆ â†’ å¤šå°ºåº¦TKAN â†’ ä¸ç¡®å®šæ€§ä¼°è®¡ â†’ é¢„æµ‹è¾“å‡º
     â†“          â†“          â†“           â†“            â†“           â†“
  æ—¶åº+å›¾åƒ   ç‰¹å¾æå–   è·¨æ¨¡æ€äº¤äº’   æ—¶åºå»ºæ¨¡     ç½®ä¿¡åŒºé—´    è‚¡ä»·+æ–¹å·®
  æ–‡æœ¬+è´¢åŠ¡   ç»´åº¦ç»Ÿä¸€   æƒé‡åˆ†é…    å¤šå°ºåº¦      é£é™©é‡åŒ–    æ¶¨è·Œæ¦‚ç‡
```

#### ä¸»è¦ç»„ä»¶

1. **æ¨¡æ€ç¼–ç å™¨**
   - æ–‡æœ¬ç¼–ç å™¨ï¼šBERTæˆ–ç®€åŒ–æƒ…æ„Ÿç¼–ç å™¨
   - å›¾åƒç¼–ç å™¨ï¼šé¢„è®­ç»ƒCNNæˆ–è‡ªå®šä¹‰CNN
   - æ—¶åºç¼–ç å™¨ï¼šçº¿æ€§å˜æ¢å’Œå½’ä¸€åŒ–
   - è´¢åŠ¡ç¼–ç å™¨ï¼šç‰¹å¾é€‰æ‹©å’Œæ ‡å‡†åŒ–

2. **æ³¨æ„åŠ›èåˆæ¨¡å—**
   ```python
   # è·¨æ¨¡æ€æ³¨æ„åŠ›
   attention_weights = softmax(Q_text @ K_image^T)
   fused_features = attention_weights @ V_image
   ```

3. **å¤šå°ºåº¦TKAN**
   - çŸ­æœŸå°ºåº¦ï¼š5-10å¤©æ¨¡å¼
   - ä¸­æœŸå°ºåº¦ï¼š20-30å¤©å‘¨æœŸ
   - é•¿æœŸå°ºåº¦ï¼šå…¨åºåˆ—ä¾èµ–

4. **ä¸ç¡®å®šæ€§ä¼°è®¡**
   ```python
   # é«˜æ–¯è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±
   mean, log_var = model(x)
   loss = 0.5 * (log_var + (y - mean)^2 / exp(log_var))
   ```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from models.advanced_model import AdvancedMultimodalStockPredictor

# åˆ›å»ºé«˜çº§æ¨¡å‹
model = AdvancedMultimodalStockPredictor(
    time_series_dim=6,
    text_dim=128,
    image_dim=64,
    table_dim=6,
    use_bert=True,
    use_pretrained_image=True,
    estimate_uncertainty=True
)

# å‰å‘ä¼ æ’­
output = model(batch_data)
mean_pred = output['mean']      # é¢„æµ‹å‡å€¼
var_pred = output['variance']   # é¢„æµ‹æ–¹å·®
confidence = output['confidence']  # ç½®ä¿¡åŒºé—´
```

### ğŸ“ models/text_encoder.py - æ–‡æœ¬ç¼–ç å™¨

#### æ ¸å¿ƒåŸç†
å°†æ–°é—»æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼ç‰¹å¾å‘é‡ï¼š

```
åŸå§‹æ–‡æœ¬ â†’ åˆ†è¯ â†’ BERTç¼–ç  â†’ æ± åŒ– â†’ æ—¶åºèšåˆ â†’ æ–‡æœ¬ç‰¹å¾å‘é‡
   â†“        â†“       â†“        â†“        â†“          â†“
æ–°é—»æ ‡é¢˜   Token   è¯­ä¹‰è¡¨ç¤º  å¥å­å‘é‡  å¤šæ–°é—»èåˆ  128ç»´ç‰¹å¾
```

#### ä¸¤ç§ç¼–ç æ–¹å¼

1. **BERTç¼–ç å™¨**ï¼ˆé«˜çº§ç‰ˆï¼‰
   ```python
   # ä½¿ç”¨é¢„è®­ç»ƒBERTæ¨¡å‹
   from transformers import BertModel, BertTokenizer
   
   tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
   bert_model = BertModel.from_pretrained('bert-base-chinese')
   ```

2. **ç®€åŒ–ç¼–ç å™¨**ï¼ˆåŸºç¡€ç‰ˆï¼‰
   ```python
   # å°†1ç»´æƒ…æ„Ÿåˆ†æ•°æ‰©å±•ä¸º128ç»´ç‰¹å¾
   features = self.feature_expansion(sentiment_score)
   ```

#### å…³é”®æŠ€æœ¯

1. **æ—¶åºèšåˆ**
   - å¤„ç†æ¯å¤©å¤šæ¡æ–°é—»
   - LSTMèšåˆæ—¶åºä¿¡æ¯
   - æ³¨æ„åŠ›æƒé‡åˆ†é…

2. **æƒ…æ„Ÿåˆ†æå¢å¼º**
   - é‡‘èè¯å…¸æƒ…æ„Ÿåˆ†æ
   - ä¸Šä¸‹æ–‡è¯­ä¹‰ç†è§£
   - æƒ…æ„Ÿå¼ºåº¦é‡åŒ–

#### ä½¿ç”¨ç¤ºä¾‹

```python
from models.text_encoder import create_text_encoder

# åˆ›å»ºæ–‡æœ¬ç¼–ç å™¨
text_encoder = create_text_encoder(
    use_bert=True,      # ä½¿ç”¨BERTï¼ˆå¦‚æœå¯ç”¨ï¼‰
    output_dim=128,     # è¾“å‡ºç»´åº¦
    max_length=128      # æœ€å¤§æ–‡æœ¬é•¿åº¦
)

# ç¼–ç æ–‡æœ¬
texts = ["è‚¡å¸‚ä¸Šæ¶¨", "ç»æµå¢é•¿æ”¾ç¼“"]
features = text_encoder(texts)  # (batch, seq_len, 128)
```

### ğŸ–¼ï¸ models/image_encoder.py - å›¾åƒç¼–ç å™¨

#### æ ¸å¿ƒåŸç†
ä»Kçº¿å›¾ä¸­æå–æŠ€æœ¯å½¢æ€ç‰¹å¾ï¼š

```
Kçº¿å›¾åƒ â†’ CNNç‰¹å¾æå– â†’ å…¨å±€æ± åŒ– â†’ ç‰¹å¾å‹ç¼© â†’ å›¾åƒç‰¹å¾å‘é‡
   â†“          â†“           â†“         â†“          â†“
PNGæ–‡ä»¶   å·ç§¯+æ± åŒ–    ç©ºé—´èšåˆ   ç»´åº¦é™ä½    64ç»´ç‰¹å¾
```

#### ä¸¤ç§å®ç°æ–¹å¼

1. **åŸºç¡€CNNç¼–ç å™¨**
   ```python
   # è‡ªå®šä¹‰CNNæ¶æ„
   self.cnn = nn.Sequential(
       nn.Conv2d(1, 32, 3, padding=1),
       nn.ReLU(),
       nn.MaxPool2d(2),
       # ... æ›´å¤šå±‚
   )
   ```

2. **é«˜çº§é¢„è®­ç»ƒç¼–ç å™¨**
   ```python
   # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
   import timm
   self.backbone = timm.create_model(
       'efficientnet_b0',
       pretrained=True,
       in_chans=1,
       num_classes=0
   )
   ```

#### æŠ€æœ¯ç‰¹è‰²

1. **Kçº¿æ¨¡å¼è¯†åˆ«**
   - å¤´è‚©é¡¶ã€åŒåº•ç­‰ç»å…¸å½¢æ€
   - æ”¯æ’‘é˜»åŠ›ä½è¯†åˆ«
   - è¶‹åŠ¿çº¿æ£€æµ‹

2. **æŠ€æœ¯æŒ‡æ ‡æå–**
   - ç§»åŠ¨å¹³å‡çº¿å½¢æ€
   - æˆäº¤é‡æ¨¡å¼
   - æ³¢åŠ¨ç‡ç‰¹å¾

#### ä½¿ç”¨ç¤ºä¾‹

```python
from models.image_encoder import create_image_encoder

# åˆ›å»ºå›¾åƒç¼–ç å™¨
image_encoder = create_image_encoder(
    feature_dim=64,
    use_pretrained=True,
    use_ensemble=False
)

# ç¼–ç å›¾åƒ
images = torch.randn(32, 1, 224, 224)  # ç°åº¦Kçº¿å›¾
features = image_encoder(images)        # (32, 64)
```

### ğŸ”€ models/fusion.py - å¤šæ¨¡æ€èåˆ

#### æ ¸å¿ƒåŸç†
æ™ºèƒ½èåˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼š

```
å„æ¨¡æ€ç‰¹å¾ â†’ æ³¨æ„åŠ›è®¡ç®— â†’ æƒé‡åˆ†é… â†’ ç‰¹å¾èåˆ â†’ èåˆè¡¨ç¤º
     â†“          â†“          â†“         â†“         â†“
æ—¶åº+å›¾åƒ    è·¨æ¨¡æ€äº¤äº’   åŠ¨æ€æƒé‡   åŠ æƒæ±‚å’Œ   ç»Ÿä¸€ç‰¹å¾
æ–‡æœ¬+è´¢åŠ¡    ç›¸å…³æ€§è®¡ç®—   é‡è¦æ€§     ä¿¡æ¯æ•´åˆ   256ç»´å‘é‡
```

#### èåˆç­–ç•¥

1. **è·¨æ¨¡æ€æ³¨æ„åŠ›**
   ```python
   # è®¡ç®—æ¨¡æ€é—´çš„æ³¨æ„åŠ›æƒé‡
   attention_scores = torch.matmul(Q_modal1, K_modal2.transpose(-2, -1))
   attention_weights = F.softmax(attention_scores / sqrt(d_k), dim=-1)
   fused_features = torch.matmul(attention_weights, V_modal2)
   ```

2. **é—¨æ§èåˆæœºåˆ¶**
   ```python
   # å­¦ä¹ æ¯ä¸ªæ¨¡æ€çš„é‡è¦æ€§
   gate_text = torch.sigmoid(self.gate_text(text_features))
   gate_image = torch.sigmoid(self.gate_image(image_features))
   
   fused = gate_text * text_features + gate_image * image_features
   ```

3. **è‡ªé€‚åº”æƒé‡åˆ†é…**
   - æ ¹æ®æ•°æ®è´¨é‡åŠ¨æ€è°ƒæ•´æƒé‡
   - å¤„ç†æ¨¡æ€ç¼ºå¤±æƒ…å†µ
   - é¿å…æŸä¸ªæ¨¡æ€ä¸»å¯¼

#### ä½¿ç”¨ç¤ºä¾‹

```python
from models.fusion import AdvancedMultimodalFusion

# åˆ›å»ºèåˆæ¨¡å—
fusion = AdvancedMultimodalFusion(
    input_dims=[6, 128, 64, 6],  # å„æ¨¡æ€ç»´åº¦
    embed_dim=64,                # åµŒå…¥ç»´åº¦
    num_heads=4,                 # æ³¨æ„åŠ›å¤´æ•°
    output_dim=256               # è¾“å‡ºç»´åº¦
)

# èåˆå¤šæ¨¡æ€ç‰¹å¾
modality_features = {
    'time_series': time_features,
    'text': text_features,
    'image': image_features,
    'table': table_features
}

fused_features = fusion(modality_features)  # (batch, seq_len, 256)
```

---

## å·¥å…·å‡½æ•°æ¨¡å—

### ğŸ“Š utils/metrics.py - è¯„ä¼°æŒ‡æ ‡

#### æ ¸å¿ƒåŸç†
æä¾›å…¨é¢çš„æ¨¡å‹æ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼š

```
é¢„æµ‹ç»“æœ â†’ åŸºç¡€æŒ‡æ ‡ â†’ é‡‘èæŒ‡æ ‡ â†’ é£é™©æŒ‡æ ‡ â†’ ç»¼åˆè¯„ä¼°
   â†“         â†“         â†“         â†“         â†“
çœŸå®å€¼    MSE/MAE    å¤æ™®æ¯”ç‡   æœ€å¤§å›æ’¤   æ¨¡å‹è´¨é‡
é¢„æµ‹å€¼    RÂ²/RMSE    ç´¢æè¯ºæ¯”   èƒœç‡      æŠ•èµ„ä»·å€¼
```

#### æŒ‡æ ‡åˆ†ç±»

1. **åŸºç¡€å›å½’æŒ‡æ ‡**
   ```python
   # å‡æ–¹è¯¯å·®
   mse = torch.mean((y_true - y_pred) ** 2)
   
   # å†³å®šç³»æ•°
   ss_res = torch.sum((y_true - y_pred) ** 2)
   ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)
   r2 = 1 - ss_res / ss_tot
   ```

2. **é‡‘èä¸“ç”¨æŒ‡æ ‡**
   ```python
   # å¤æ™®æ¯”ç‡
   returns = y_pred  # é¢„æµ‹æ”¶ç›Šç‡
   sharpe_ratio = torch.mean(returns) / torch.std(returns)
   
   # æ–¹å‘å‡†ç¡®ç‡
   direction_accuracy = torch.mean(
       (torch.sign(y_true) == torch.sign(y_pred)).float()
   )
   ```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from utils.metrics import calculate_comprehensive_metrics

# è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
y_true = torch.randn(1000, 24)  # çœŸå®æ”¶ç›Šç‡
y_pred = torch.randn(1000, 24)  # é¢„æµ‹æ”¶ç›Šç‡

metrics = calculate_comprehensive_metrics(y_true, y_pred)

print(f"RÂ²: {metrics['r2']:.4f}")
print(f"å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.4f}")
print(f"æ–¹å‘å‡†ç¡®ç‡: {metrics['direction_accuracy']:.4f}")
```

### ğŸ’° utils/financial_metrics.py - é‡‘èæŒ‡æ ‡

#### æ ¸å¿ƒåŸç†
ä¸“é—¨é’ˆå¯¹é‡‘èæ—¶åºæ•°æ®çš„è¯„ä¼°æŒ‡æ ‡ï¼š

```
æ”¶ç›Šåºåˆ— â†’ é£é™©è®¡ç®— â†’ æ”¶ç›Šåˆ†æ â†’ å›æ’¤åˆ†æ â†’ äº¤æ˜“ç»Ÿè®¡
   â†“         â†“         â†“         â†“         â†“
é¢„æµ‹æ”¶ç›Š   æ³¢åŠ¨ç‡    ç´¯è®¡æ”¶ç›Š   æœ€å¤§å›æ’¤   èƒœç‡ç»Ÿè®¡
çœŸå®æ”¶ç›Š   VaR      å¹´åŒ–æ”¶ç›Š   å›æ’¤æŒç»­   ç›ˆäºæ¯”
```

#### å…³é”®æŒ‡æ ‡

1. **é£é™©è°ƒæ•´æ”¶ç›Š**
   ```python
   # å¤æ™®æ¯”ç‡ï¼šè¶…é¢æ”¶ç›Š/æ³¢åŠ¨ç‡
   sharpe = (mean_return - risk_free_rate) / std_return
   
   # ç´¢æè¯ºæ¯”ç‡ï¼šè¶…é¢æ”¶ç›Š/ä¸‹è¡Œæ³¢åŠ¨ç‡
   downside_std = std(returns[returns < 0])
   sortino = (mean_return - risk_free_rate) / downside_std
   ```

2. **å›æ’¤åˆ†æ**
   ```python
   # æœ€å¤§å›æ’¤
   cumulative_returns = (1 + returns).cumprod()
   running_max = cumulative_returns.cummax()
   drawdown = (cumulative_returns - running_max) / running_max
   max_drawdown = drawdown.min()
   ```

3. **äº¤æ˜“ç»Ÿè®¡**
   ```python
   # èƒœç‡
   win_rate = (returns > 0).mean()
   
   # ç›ˆäºæ¯”
   avg_win = returns[returns > 0].mean()
   avg_loss = returns[returns < 0].mean()
   profit_loss_ratio = avg_win / abs(avg_loss)
   ```

### ğŸ¨ utils/visualization.py - å¯è§†åŒ–å·¥å…·

#### æ ¸å¿ƒåŸç†
æä¾›ä¸°å¯Œçš„æ•°æ®å’Œç»“æœå¯è§†åŒ–åŠŸèƒ½ï¼š

```
æ•°æ®/ç»“æœ â†’ å›¾è¡¨ç”Ÿæˆ â†’ æ ·å¼ç¾åŒ– â†’ äº¤äº’åŠŸèƒ½ â†’ å¯è§†åŒ–è¾“å‡º
    â†“         â†“         â†“         â†“         â†“
è®­ç»ƒå†å²   æ—¶åºå›¾è¡¨   é¢œè‰²ä¸»é¢˜   ç¼©æ”¾å¹³ç§»   PNG/HTML
é¢„æµ‹ç»“æœ   æ•£ç‚¹å›¾    å›¾ä¾‹æ ‡æ³¨   å·¥å…·æç¤º   ä¿å­˜åˆ†äº«
```

#### å¯è§†åŒ–ç±»å‹

1. **è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–**
   ```python
   # æŸå¤±æ›²çº¿
   plt.plot(train_losses, label='Training Loss')
   plt.plot(val_losses, label='Validation Loss')
   
   # å­¦ä¹ ç‡å˜åŒ–
   plt.plot(learning_rates, label='Learning Rate')
   ```

2. **é¢„æµ‹ç»“æœå¯è§†åŒ–**
   ```python
   # é¢„æµ‹vsçœŸå®å€¼
   plt.scatter(y_true, y_pred, alpha=0.6)
   plt.plot([y_true.min(), y_true.max()], 
            [y_true.min(), y_true.max()], 'r--')
   
   # æ—¶åºé¢„æµ‹å›¾
   plt.plot(dates, y_true, label='Actual', linewidth=2)
   plt.plot(dates, y_pred, label='Predicted', linewidth=2)
   ```

3. **ä¸ç¡®å®šæ€§å¯è§†åŒ–**
   ```python
   # ç½®ä¿¡åŒºé—´
   plt.fill_between(dates, 
                    y_pred - 1.96*std_pred,
                    y_pred + 1.96*std_pred,
                    alpha=0.3, label='95% Confidence')
   ```

---

## é…ç½®ç®¡ç†æ¨¡å—

### âš™ï¸ configs/config.py - åŸºç¡€é…ç½®

#### æ ¸å¿ƒåŸç†
é›†ä¸­ç®¡ç†æ‰€æœ‰ç³»ç»Ÿå‚æ•°ï¼š

```
é…ç½®æ–‡ä»¶ â†’ å‚æ•°è§£æ â†’ ç±»å‹æ£€æŸ¥ â†’ é»˜è®¤å€¼ â†’ é…ç½®å¯¹è±¡
   â†“         â†“         â†“         â†“        â†“
YAML/JSON  å­—å…¸è½¬æ¢   æ•°æ®éªŒè¯   ç¼ºå¤±è¡¥å…¨  Pythonç±»
```

#### é…ç½®ç»“æ„

```python
@dataclass
class Config:
    data: DataConfig        # æ•°æ®ç›¸å…³é…ç½®
    model: ModelConfig      # æ¨¡å‹ç›¸å…³é…ç½®
    train: TrainConfig      # è®­ç»ƒç›¸å…³é…ç½®
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from configs.config import Config

# åŠ è½½é»˜è®¤é…ç½®
config = Config()

# ä¿®æ”¹é…ç½®
config.train.epochs = 50
config.train.batch_size = 64
config.model.hidden_size = 256

# ä½¿ç”¨é…ç½®
model = create_model(config.model)
dataset = create_dataset(config.data)
```

### ğŸš€ configs/advanced_config.py - é«˜çº§é…ç½®

#### æ ¸å¿ƒåŸç†
ä¸ºé«˜çº§åŠŸèƒ½æä¾›ä¸“é—¨çš„é…ç½®ç®¡ç†ï¼š

```
é«˜çº§é…ç½® â†’ åŠŸèƒ½å¼€å…³ â†’ èµ„æºåˆ†é… â†’ æ€§èƒ½ä¼˜åŒ– â†’ é«˜çº§æ¨¡å‹
   â†“         â†“         â†“         â†“         â†“
BERTå¼€å…³   GPUå†…å­˜    æ‰¹é‡å¤§å°   æ··åˆç²¾åº¦   æ³¨æ„åŠ›å±‚æ•°
é¢„è®­ç»ƒæ¨¡å‹  å¤šè¿›ç¨‹     å­¦ä¹ ç‡     æ¢¯åº¦ç´¯ç§¯   èåˆç»´åº¦
```

#### é…ç½®é¢„è®¾

1. **å¿«é€Ÿæµ‹è¯•é…ç½®**
   ```python
   def get_fast_test_config():
       config = AdvancedConfig()
       config.data.stocks = 3
       config.train.epochs = 3
       config.model.use_bert = False
       return config
   ```

2. **ç”Ÿäº§ç¯å¢ƒé…ç½®**
   ```python
   def get_production_config():
       config = AdvancedConfig()
       config.model.use_bert = True
       config.model.use_pretrained_image = True
       config.train.mixed_precision = True
       return config
   ```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from configs.advanced_config import get_advanced_config

# åŠ è½½é«˜çº§é…ç½®
config = get_advanced_config()

# åˆ›å»ºé«˜çº§æ¨¡å‹
model = AdvancedMultimodalStockPredictor(
    **config.model.__dict__
)
```

---

## ğŸ¯ æ¨¡å—åä½œæµç¨‹

### å®Œæ•´çš„è®­ç»ƒæµç¨‹

```mermaid
graph TD
    A[é…ç½®åŠ è½½] --> B[æ•°æ®é›†åˆ›å»º]
    B --> C[æ•°æ®åŠ è½½å™¨]
    C --> D[æ¨¡å‹åˆå§‹åŒ–]
    D --> E[è®­ç»ƒå¾ªç¯]
    E --> F[æ¨¡å‹è¯„ä¼°]
    F --> G[ç»“æœå¯è§†åŒ–]
    
    E --> E1[å‰å‘ä¼ æ’­]
    E1 --> E2[æŸå¤±è®¡ç®—]
    E2 --> E3[åå‘ä¼ æ’­]
    E3 --> E4[å‚æ•°æ›´æ–°]
    E4 --> E1
```

### é¢„æµ‹æµç¨‹

```mermaid
graph TD
    A[è¾“å…¥æ•°æ®] --> B[æ•°æ®é¢„å¤„ç†]
    B --> C[æ¨¡æ€ç¼–ç ]
    C --> D[ç‰¹å¾èåˆ]
    D --> E[TKANå»ºæ¨¡]
    E --> F[ä¸ç¡®å®šæ€§ä¼°è®¡]
    F --> G[é¢„æµ‹è¾“å‡º]
    
    C --> C1[æ–‡æœ¬ç¼–ç ]
    C --> C2[å›¾åƒç¼–ç ]
    C --> C3[æ—¶åºç¼–ç ]
    C --> C4[è´¢åŠ¡ç¼–ç ]
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. æ¨¡å‹é€‰æ‹©å»ºè®®

- **èµ„æºå—é™**ï¼šä½¿ç”¨åŸºç¡€é…ç½®ï¼Œå…³é—­BERTå’Œé¢„è®­ç»ƒæ¨¡å‹
- **è¿½æ±‚æ€§èƒ½**ï¼šä½¿ç”¨é«˜çº§é…ç½®ï¼Œå¼€å¯æ‰€æœ‰åŠŸèƒ½
- **å¿«é€ŸéªŒè¯**ï¼šä½¿ç”¨å¿«é€Ÿæµ‹è¯•é…ç½®ï¼Œå°‘é‡æ•°æ®å’Œè½®æ¬¡

### 2. å‚æ•°è°ƒä¼˜å»ºè®®

- **å­¦ä¹ ç‡**ï¼šä»0.001å¼€å§‹ï¼Œæ ¹æ®æŸå¤±æ›²çº¿è°ƒæ•´
- **æ‰¹é‡å¤§å°**ï¼šæ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼Œé€šå¸¸32-128
- **åºåˆ—é•¿åº¦**ï¼š30-60å¤©å†å²æ•°æ®æ•ˆæœè¾ƒå¥½
- **éšè—ç»´åº¦**ï¼š128-512ï¼Œæ ¹æ®æ•°æ®å¤æ‚åº¦è°ƒæ•´

### 3. æ€§èƒ½ä¼˜åŒ–å»ºè®®

- **æ•°æ®å¹¶è¡Œ**ï¼šä½¿ç”¨å¤šGPUè®­ç»ƒ
- **æ··åˆç²¾åº¦**ï¼šå¼€å¯FP16è®­ç»ƒ
- **æ¢¯åº¦ç´¯ç§¯**ï¼šå†…å­˜ä¸è¶³æ—¶ä½¿ç”¨
- **æ¨¡å‹å‰ªæ**ï¼šéƒ¨ç½²æ—¶å‹ç¼©æ¨¡å‹

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0  
**æœ€åæ›´æ–°**: 2025-10-08  
**ç»´æŠ¤è€…**: HS300é¡¹ç›®å›¢é˜Ÿ
