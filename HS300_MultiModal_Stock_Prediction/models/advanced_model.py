"""
é«˜çº§å¤šæ¨¡æ€è‚¡ç¥¨é¢„æµ‹æ¨¡å‹
æ•´åˆæ‰€æœ‰æ”¹è¿›ï¼šBERTæ–‡æœ¬ã€æ³¨æ„åŠ›èåˆã€å¤šå°ºåº¦TKANã€ä¸ç¡®å®šæ€§ä¼°è®¡
"""
import torch
import torch.nn as nn
from typing import Dict, Optional, Tuple

from models.text_encoder import create_text_encoder, SimpleSentimentEncoder
from models.image_encoder_advanced import create_image_encoder
from models.fusion import AdvancedMultimodalFusion, AdaptiveModalityFusion
from models.multiscale_tkan import MultiScaleMultimodalTKAN
from models.uncertainty import UncertaintyHead


class AdvancedMultimodalStockPredictor(nn.Module):
    """
    é«˜çº§å¤šæ¨¡æ€è‚¡ç¥¨é¢„æµ‹å™¨
    
    æ¶æ„æµç¨‹:
    1. å„æ¨¡æ€ç‹¬ç«‹ç¼–ç ï¼ˆæ—¶åºã€æ–‡æœ¬ã€å›¾åƒã€è´¢åŠ¡ï¼‰
    2. é«˜çº§èåˆï¼ˆæ³¨æ„åŠ›æœºåˆ¶ + é—¨æ§èåˆï¼‰
    3. å¤šå°ºåº¦æ—¶åºå»ºæ¨¡ï¼ˆTKANï¼‰
    4. ä¸ç¡®å®šæ€§ä¼°è®¡ï¼ˆå‡å€¼ + æ–¹å·®ï¼‰
    """
    
    def __init__(
        self,
        # æ¨¡æ€ç»´åº¦é…ç½®
        time_series_dim: int = 6,
        text_dim: int = 128,  # BERTè¾“å‡ºç»´åº¦
        image_dim: int = 64,
        table_dim: int = 6,
        
        # èåˆé…ç½®
        fusion_embed_dim: int = 64,
        fusion_num_heads: int = 4,
        fusion_output_dim: int = 256,
        
        # TKANé…ç½®
        tkan_hidden_size: int = 128,
        tkan_num_layers: int = 2,
        tkan_scales: list = None,
        
        # è¾“å‡ºé…ç½®
        output_size: int = 24,
        
        # ç‰¹å¾æå–å™¨é…ç½®
        use_bert: bool = False,  # æ˜¯å¦ä½¿ç”¨BERTï¼ˆéœ€è¦transformersåº“ï¼‰
        use_pretrained_image: bool = False,  # æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒå›¾åƒæ¨¡å‹
        
        # ä¸ç¡®å®šæ€§ä¼°è®¡
        estimate_uncertainty: bool = True,
        
        dropout: float = 0.2
    ):
        super().__init__()
        
        self.estimate_uncertainty = estimate_uncertainty
        
        # 1. æ–‡æœ¬ç¼–ç å™¨
        if use_bert:
            try:
                self.text_encoder = create_text_encoder(
                    use_bert=True,
                    output_dim=text_dim
                )
                print("âœ… Using BERT text encoder")
            except:
                print("âš ï¸  BERT not available, using simple encoder")
                self.text_encoder = SimpleSentimentEncoder(output_dim=text_dim)
        else:
            self.text_encoder = SimpleSentimentEncoder(output_dim=text_dim)
        
        # 2. å›¾åƒç¼–ç å™¨
        self.image_encoder = create_image_encoder(
            feature_dim=image_dim,
            use_pretrained=use_pretrained_image
        )
        
        # 3. æ—¶åºå’Œè´¢åŠ¡ç‰¹å¾æŠ•å½±
        self.time_series_projection = nn.Sequential(
            nn.Linear(time_series_dim, 32),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(32, time_series_dim)
        )
        
        self.table_projection = nn.Sequential(
            nn.Linear(table_dim, 16),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(16, table_dim)
        )
        
        # 4. é«˜çº§å¤šæ¨¡æ€èåˆ
        modality_dims = {
            'time_series': time_series_dim,
            'text': text_dim,
            'image': image_dim,
            'table': table_dim
        }
        
        self.fusion = AdvancedMultimodalFusion(
            modality_dims=modality_dims,
            embed_dim=fusion_embed_dim,
            num_heads=fusion_num_heads,
            num_fusion_layers=2,
            output_dim=fusion_output_dim,
            dropout=dropout
        )
        
        # 5. å¤šå°ºåº¦TKAN
        if tkan_scales is None:
            tkan_scales = [1, 3, 5]
        
        self.multiscale_tkan = MultiScaleMultimodalTKAN(
            input_size=fusion_output_dim,
            hidden_size=tkan_hidden_size,
            output_size=output_size,
            num_layers=tkan_num_layers,
            scales=tkan_scales,
            dropout=dropout
        )
        
        # 6. ä¸ç¡®å®šæ€§ä¼°è®¡ï¼ˆå¯é€‰ï¼‰
        if estimate_uncertainty:
            self.uncertainty_head = UncertaintyHead(
                input_dim=fusion_output_dim,  # ä½¿ç”¨èåˆåçš„ç»´åº¦
                output_dim=output_size
            )
    
    def extract_modality_features(
        self,
        time_series: torch.Tensor,
        text: torch.Tensor,
        image: torch.Tensor,
        table: torch.Tensor
    ) -> Dict[str, torch.Tensor]:
        """
        æå–å„æ¨¡æ€ç‰¹å¾
        
        Args:
            time_series: (batch, seq_len, 6)
            text: (batch, seq_len, 1) æƒ…æ„Ÿå¾—åˆ†
            image: (batch, 1, H, W) Kçº¿å›¾
            table: (batch, seq_len, 6) è´¢åŠ¡æ•°æ®
        
        Returns:
            features: å„æ¨¡æ€ç‰¹å¾å­—å…¸
        """
        batch_size, seq_len, _ = time_series.shape
        
        # 1. æ—¶åºç‰¹å¾ï¼ˆä¿æŒåºåˆ—ï¼‰
        ts_features = self.time_series_projection(time_series)  # (batch, seq_len, 6)
        
        # 2. æ–‡æœ¬ç‰¹å¾ï¼ˆä»æƒ…æ„Ÿå¾—åˆ†æ‰©å±•ï¼‰
        text_features = self.text_encoder(text)  # (batch, seq_len, text_dim)
        
        # 3. å›¾åƒç‰¹å¾ï¼ˆæ¯ä¸ªæ ·æœ¬ä¸€å¼ å›¾ï¼‰
        img_features = self.image_encoder(image)  # (batch, image_dim)
        # æ‰©å±•åˆ°åºåˆ—
        img_features = img_features.unsqueeze(1).expand(-1, seq_len, -1)
        
        # 4. è´¢åŠ¡ç‰¹å¾
        table_features = self.table_projection(table)  # (batch, seq_len, 6)
        
        return {
            'time_series': ts_features,
            'text': text_features,
            'image': img_features,
            'table': table_features
        }
    
    def forward(
        self,
        time_series: torch.Tensor,
        text: torch.Tensor,
        image: torch.Tensor,
        table: torch.Tensor,
        return_uncertainty: bool = False
    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            time_series: (batch, seq_len, 6)
            text: (batch, seq_len, 1)
            image: (batch, 1, H, W)
            table: (batch, seq_len, 6)
            return_uncertainty: æ˜¯å¦è¿”å›ä¸ç¡®å®šæ€§
        
        Returns:
            predictions: (batch, output_size) é¢„æµ‹å€¼
            uncertainty: (batch, output_size) ä¸ç¡®å®šæ€§ï¼ˆå¯é€‰ï¼‰
        """
        batch_size, seq_len, _ = time_series.shape
        
        # 1. æå–å„æ¨¡æ€ç‰¹å¾
        modality_features = self.extract_modality_features(
            time_series, text, image, table
        )
        
        # 2. é€æ—¶é—´æ­¥èåˆï¼ˆç®€åŒ–ç‰ˆï¼šåªèåˆæœ€åæ—¶åˆ»ï¼‰
        # å–æ¯ä¸ªæ¨¡æ€çš„æœ€åæ—¶åˆ»ç‰¹å¾
        last_step_features = {
            k: v[:, -1, :] for k, v in modality_features.items()
        }

        # èåˆ
        fused_features = self.fusion(last_step_features)  # (batch, fusion_output_dim)

        # æ‰©å±•åˆ°åºåˆ— - ä½¿ç”¨contiguousé¿å…å†…å­˜é—®é¢˜
        fused_sequence = fused_features.unsqueeze(1).expand(batch_size, seq_len, -1).contiguous()
        
        # 3. å¤šå°ºåº¦TKAN
        predictions = self.multiscale_tkan(fused_sequence)  # (batch, output_size)

        # 4. ä¸ç¡®å®šæ€§ä¼°è®¡ï¼ˆå¯é€‰ï¼‰
        if return_uncertainty and self.estimate_uncertainty:
            # ä½¿ç”¨èåˆåçš„æœ€åæ—¶åˆ»ç‰¹å¾ä¼°è®¡ä¸ç¡®å®šæ€§
            # fused_features: (batch, fusion_output_dim)
            mean, var = self.uncertainty_head(fused_features)
            return mean, var

        return predictions, None
    
    def predict_with_confidence(
        self,
        time_series: torch.Tensor,
        text: torch.Tensor,
        image: torch.Tensor,
        table: torch.Tensor,
        confidence_level: float = 0.95
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        é¢„æµ‹å¹¶è¿”å›ç½®ä¿¡åŒºé—´
        
        Returns:
            mean: é¢„æµ‹å‡å€¼
            lower: ä¸‹ç•Œ
            upper: ä¸Šç•Œ
        """
        if not self.estimate_uncertainty:
            predictions, _ = self.forward(time_series, text, image, table)
            return predictions, predictions, predictions
        
        mean, var = self.forward(
            time_series, text, image, table, 
            return_uncertainty=True
        )
        
        std = torch.sqrt(var)
        
        # è®¡ç®—ç½®ä¿¡åŒºé—´ï¼ˆå‡è®¾æ­£æ€åˆ†å¸ƒï¼‰
        from scipy import stats
        z_score = stats.norm.ppf((1 + confidence_level) / 2)
        
        lower = mean - z_score * std
        upper = mean + z_score * std
        
        return mean, lower, upper


def create_advanced_model(config: dict) -> AdvancedMultimodalStockPredictor:
    """
    å·¥å‚å‡½æ•°ï¼šæ ¹æ®é…ç½®åˆ›å»ºé«˜çº§æ¨¡å‹
    
    Args:
        config: é…ç½®å­—å…¸
    
    Returns:
        model: é«˜çº§å¤šæ¨¡æ€æ¨¡å‹
    """
    model = AdvancedMultimodalStockPredictor(
        time_series_dim=config.get('time_series_dim', 6),
        text_dim=config.get('text_dim', 128),
        image_dim=config.get('image_dim', 64),
        table_dim=config.get('table_dim', 6),
        fusion_embed_dim=config.get('fusion_embed_dim', 64),
        fusion_output_dim=config.get('fusion_output_dim', 256),
        tkan_hidden_size=config.get('tkan_hidden_size', 128),
        tkan_num_layers=config.get('tkan_num_layers', 2),
        output_size=config.get('output_size', 24),
        use_bert=config.get('use_bert', False),
        use_pretrained_image=config.get('use_pretrained_image', False),
        estimate_uncertainty=config.get('estimate_uncertainty', True),
        dropout=config.get('dropout', 0.2)
    )
    
    # ç»Ÿè®¡å‚æ•°
    num_params = sum(p.numel() for p in model.parameters())
    print(f"\n{'='*70}")
    print(f"ğŸš€ Advanced Multimodal Stock Predictor Created")
    print(f"{'='*70}")
    print(f"ğŸ“Š Model Configuration:")
    print(f"  - Time Series Dim: {config.get('time_series_dim', 6)}")
    print(f"  - Text Dim: {config.get('text_dim', 128)}")
    print(f"  - Image Dim: {config.get('image_dim', 64)}")
    print(f"  - Table Dim: {config.get('table_dim', 6)}")
    print(f"  - Fusion Output: {config.get('fusion_output_dim', 256)}")
    print(f"  - TKAN Hidden: {config.get('tkan_hidden_size', 128)}")
    print(f"  - Output Size: {config.get('output_size', 24)}")
    print(f"\nğŸ“ˆ Model Statistics:")
    print(f"  - Total Parameters: {num_params:,}")
    print(f"  - Uncertainty Estimation: {config.get('estimate_uncertainty', True)}")
    print(f"{'='*70}\n")
    
    return model


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("Testing Advanced Multimodal Model...")
    
    # é…ç½®
    config = {
        'time_series_dim': 6,
        'text_dim': 128,
        'image_dim': 64,
        'table_dim': 6,
        'fusion_output_dim': 256,
        'tkan_hidden_size': 128,
        'output_size': 24,
        'use_bert': False,
        'use_pretrained_image': False,
        'estimate_uncertainty': True
    }
    
    # åˆ›å»ºæ¨¡å‹
    model = create_advanced_model(config)
    
    # æµ‹è¯•æ•°æ®
    batch_size = 4
    seq_len = 60
    
    time_series = torch.randn(batch_size, seq_len, 6)
    text = torch.randn(batch_size, seq_len, 1)
    image = torch.randn(batch_size, 1, 224, 224)
    table = torch.randn(batch_size, seq_len, 6)
    
    # å‰å‘ä¼ æ’­
    predictions, _ = model(time_series, text, image, table)
    print(f"âœ… Predictions shape: {predictions.shape}")
    
    # å¸¦ä¸ç¡®å®šæ€§çš„é¢„æµ‹
    mean, var = model(time_series, text, image, table, return_uncertainty=True)
    print(f"âœ… Mean shape: {mean.shape}, Var shape: {var.shape}")
    
    print("âœ… All advanced model tests passed!")

